{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>white_elo</th>\n",
       "      <th>black_elo</th>\n",
       "      <th>moves</th>\n",
       "      <th>marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787zsVup</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>e2e4 c7c6 f2f4 d7d5 e4d5 c6d5 g1f3 b8c6 d2d3 g...</td>\n",
       "      <td>47,53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F8M8OS71</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>e2e4 c7c5 g1f3 d7d6 c2c3 g8f6 d2d3 a7a6 b1d2 e...</td>\n",
       "      <td>52,56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQSyb3KW</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>e2e4 c7c5 c2c3 d7d6 d2d4 c5d4 c3d4 b7b6 b1c3 c...</td>\n",
       "      <td>126,130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4MWQCxQ6</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>e2e4 e7e5 d2d3 b8c6 g1f3 f8c5 f1e2 g8f6 e1g1 e...</td>\n",
       "      <td>31,35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9AY2m5j</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>e2e4 c7c5 f1c4 e7e6 g1f3 d7d5 e4d5 e6d5 c4b5 b...</td>\n",
       "      <td>49,55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  white_elo  black_elo  \\\n",
       "0  787zsVup     1638.0     1851.0   \n",
       "1  F8M8OS71     1760.0     1823.0   \n",
       "2  MQSyb3KW     1877.0     1909.0   \n",
       "3  4MWQCxQ6     1741.0     1625.0   \n",
       "4  e9AY2m5j     1766.0     1733.0   \n",
       "\n",
       "                                               moves    marks  \n",
       "0  e2e4 c7c6 f2f4 d7d5 e4d5 c6d5 g1f3 b8c6 d2d3 g...    47,53  \n",
       "1  e2e4 c7c5 g1f3 d7d6 c2c3 g8f6 d2d3 a7a6 b1d2 e...    52,56  \n",
       "2  e2e4 c7c5 c2c3 d7d6 d2d4 c5d4 c3d4 b7b6 b1c3 c...  126,130  \n",
       "3  e2e4 e7e5 d2d3 b8c6 g1f3 f8c5 f1e2 g8f6 e1g1 e...    31,35  \n",
       "4  e2e4 c7c5 f1c4 e7e6 g1f3 d7d5 e4d5 e6d5 c4b5 b...    49,55  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../labeled.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [e2e4, c7c6, f2f4, d7d5, e4d5, c6d5, g1f3, b8c...\n",
       "1    [e2e4, c7c5, g1f3, d7d6, c2c3, g8f6, d2d3, a7a...\n",
       "2    [e2e4, c7c5, c2c3, d7d6, d2d4, c5d4, c3d4, b7b...\n",
       "3    [e2e4, e7e5, d2d3, b8c6, g1f3, f8c5, f1e2, g8f...\n",
       "4    [e2e4, c7c5, f1c4, e7e6, g1f3, d7d5, e4d5, e6d...\n",
       "Name: moves, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_series = data['moves'].str.split(' ')\n",
    "games_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DTYPE = torch.float64\n",
    "\n",
    "class Board2Vec(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(Board2Vec, self).__init__()\n",
    "\n",
    "        # Эмбеддинги для центральных слов\n",
    "        hidden_dim = 512\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim, dtype=DTYPE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim, dtype=DTYPE)\n",
    "        ]\n",
    "        self.target_embegging = nn.Sequential(*layers)\n",
    "        \n",
    "        # Эмбеддинги для контекста\n",
    "        hidden_dim = 512\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim, dtype=DTYPE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim, dtype=DTYPE)\n",
    "        ]\n",
    "        self.context_embedding = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, target, context):\n",
    "        # Получаем эмбеддинги для целевого и контекстного слов\n",
    "        target_embed = self.target_embegging(target)\n",
    "        context_embed = self.context_embedding(context)\n",
    "\n",
    "        # Вычисляем скалярное произведение между эмбеддингами\n",
    "        scores = torch.mul(target_embed, context_embed).sum(dim=1)\n",
    "        log_sigmoid = torch.nn.functional.logsigmoid(scores)\n",
    "        return -log_sigmoid.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import random\n",
    "from typing import List\n",
    "from collections import deque\n",
    "\n",
    "def encode_board(board: chess.Board):\n",
    "    # Инициализируем пустой вектор\n",
    "    vector = []\n",
    "    \n",
    "    # 1. Кодируем состояние доски (64 значения)\n",
    "    for square in chess.SQUARES:  # chess.SQUARES — это список всех клеток от 0 до 63\n",
    "        piece = board.piece_at(square)  # Получаем фигуру на клетке\n",
    "        if piece is None:\n",
    "            vector.append(0)  # Пустая клетка\n",
    "        else:\n",
    "            # Преобразуем фигуру в число: 1-6 для белых, -1-(-6) для черных\n",
    "            value = piece.piece_type\n",
    "            if piece.color == chess.BLACK:\n",
    "                value = -value\n",
    "            vector.append(value)\n",
    "    \n",
    "    # 2. Добавляем права на рокировку (4 бита)\n",
    "    castling_rights = [\n",
    "        board.has_kingside_castling_rights(chess.WHITE),  # Короткая рокировка белых\n",
    "        board.has_queenside_castling_rights(chess.WHITE), # Длинная рокировка белых\n",
    "        board.has_kingside_castling_rights(chess.BLACK),  # Короткая рокировка черных\n",
    "        board.has_queenside_castling_rights(chess.BLACK)  # Длинная рокировка черных\n",
    "    ]\n",
    "    vector.extend([int(right) for right in castling_rights])\n",
    "    \n",
    "    # 3. Добавляем возможность взятия на проходе (1 значение)\n",
    "    en_passant_square = board.ep_square  # Индекс клетки для взятия на проходе\n",
    "    if en_passant_square is not None:\n",
    "        vector.append(en_passant_square)\n",
    "    else:\n",
    "        vector.append(-1)  # Если взятие на проходе невозможно\n",
    "    \n",
    "    # 4. Добавляем текущего игрока (1 бит)\n",
    "    current_player = int(board.turn)  # 1 для белых, 0 для черных\n",
    "    vector.append(current_player)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "class TargetContextBoardsLoader:\n",
    "    def __init__(self, games: List[str], window_size: int, epoch_size: int):\n",
    "        self.games = games\n",
    "        self.length = len(self.games)\n",
    "        self.window_size = window_size\n",
    "        self.epoch_size = epoch_size\n",
    "        self.left = epoch_size\n",
    "        self.set_game()\n",
    "        self.prepare_game()\n",
    "\n",
    "    def set_game(self):\n",
    "        self.cur_game = random.randint(0, self.length - 1)\n",
    "        self.left -= 1\n",
    "\n",
    "    def prepare_game(self):\n",
    "        self.boards = []\n",
    "        prev_board = chess.Board()\n",
    "        game = self.games[self.cur_game]\n",
    "        for move in game:\n",
    "            prev_board.push(chess.Move.from_uci(move))\n",
    "            encoded = encode_board(prev_board)\n",
    "            self.boards.append(encoded)\n",
    "        self.cur_move = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.cur_move >= len(self.boards):\n",
    "            self.set_game()\n",
    "            if self.left < 0:\n",
    "                self.left = self.epoch_size\n",
    "                raise StopIteration\n",
    "            \n",
    "            self.prepare_game()\n",
    "\n",
    "        target = self.boards[self.cur_move]\n",
    "\n",
    "        if self.cur_move == 0:\n",
    "            self.left_context = deque()\n",
    "            self.right_context = deque()\n",
    "            for j in range(1, min(len(self.boards), 1 + self.window_size)):\n",
    "                self.right_context.append(self.boards[j])\n",
    "            self.cur_move += 1\n",
    "\n",
    "            context = list(self.left_context) + list(self.right_context)\n",
    "            return torch.tensor([target] * len(context), dtype=DTYPE), torch.tensor(context, dtype=DTYPE)\n",
    "    \n",
    "        if len(self.left_context) > 0:\n",
    "            self.left_context.popleft()\n",
    "        self.left_context.append(self.boards[self.cur_move - 1])\n",
    "\n",
    "        if self.window_size + self.cur_move < len(self.boards):\n",
    "            self.right_context.append(self.boards[self.window_size + self.cur_move])\n",
    "        self.right_context.popleft()\n",
    "        self.cur_move += 1\n",
    "\n",
    "        context = list(self.left_context) + list(self.right_context)\n",
    "        return torch.tensor([target] * len(context), dtype=DTYPE), torch.tensor(context, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = TargetContextBoardsLoader(games_series, window_size=5, epoch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 3756.2173\n",
      "Epoch [2/50], Loss: 166.6083\n",
      "Epoch [3/50], Loss: 58.5451\n",
      "Epoch [4/50], Loss: 10.9591\n",
      "Epoch [5/50], Loss: 57.6123\n",
      "Epoch [6/50], Loss: 17.5653\n",
      "Epoch [7/50], Loss: 13.7337\n",
      "Epoch [8/50], Loss: 1.1947\n",
      "Epoch [9/50], Loss: 4.9962\n",
      "Epoch [10/50], Loss: 0.3219\n",
      "Epoch [11/50], Loss: 0.0128\n",
      "Epoch [12/50], Loss: 2.9353\n",
      "Epoch [13/50], Loss: 0.3016\n",
      "Epoch [14/50], Loss: 0.9994\n",
      "Epoch [15/50], Loss: 0.0743\n",
      "Epoch [16/50], Loss: 0.3459\n",
      "Epoch [17/50], Loss: 0.1443\n",
      "Epoch [18/50], Loss: 0.0142\n",
      "Epoch [19/50], Loss: 0.1119\n",
      "Epoch [20/50], Loss: 0.2550\n",
      "Epoch [21/50], Loss: 0.0641\n",
      "Epoch [22/50], Loss: 0.4187\n",
      "Epoch [23/50], Loss: 0.0043\n",
      "Epoch [24/50], Loss: 0.0286\n",
      "Epoch [25/50], Loss: 0.0014\n",
      "Epoch [26/50], Loss: 0.0000\n",
      "Epoch [27/50], Loss: 0.0020\n",
      "Epoch [28/50], Loss: 0.0002\n",
      "Epoch [29/50], Loss: 0.0019\n",
      "Epoch [30/50], Loss: 0.0241\n",
      "Epoch [31/50], Loss: 0.0028\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target, context \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m     19\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     loss.backward()\n\u001b[32m     22\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mBoard2Vec.forward\u001b[39m\u001b[34m(self, target, context)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, context):\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Получаем эмбеддинги для целевого и контекстного слов\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     target_embed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_embegging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     context_embed = \u001b[38;5;28mself\u001b[39m.context_embedding(context)\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Вычисляем скалярное произведение между эмбеддингами\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matvey\\workspace\\heuristic_extractor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Модель\n",
    "input_dim = 70\n",
    "output_dim = 256\n",
    "model = Board2Vec(input_dim, output_dim)\n",
    "\n",
    "# Гиперпараметры\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 50\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for target, context in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(target, context)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss*100:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
